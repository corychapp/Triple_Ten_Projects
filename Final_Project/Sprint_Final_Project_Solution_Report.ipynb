{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Report\n",
    "What steps of the plan were performed and what steps were skipped (explain why)?\n",
    "\n",
    "What difficulties did you encounter and how did you manage to solve them?\n",
    "\n",
    "What were some of the key steps to solving the task?\n",
    "\n",
    "What is your final model and what quality score does it have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following steps were performed:\n",
    "\n",
    "Exploratory analysis around gender, senior citizen and characteristics of the customers have revealed some useful insights into this question, and it uncovered some useful insights into the behaviour of churned customers.\n",
    "\n",
    "1869(27%) of the customers have churned during the period from 2013-10-01 to 2020-02-01. 68 percent of the churned customers have spent $70 or more per month. There is an almost equal number of male and female customers. However, female customers, on average, spend slightly more on their Monthly bills than do male customers. Among the churned customers, 69 percent of female customers spend around 69 dollars compared to men which is 67 dollars. There are also 1142 customers that are seniorcitizens and 76 percent of them spend over 70 dollars on there monthly bills. Other behaviour I noted among the churned customers are customers with no dependents or partners tend to easily churn. Monthly billing gives them an easy exit option. As well as Paperless billing and Fiber optic internet plan have been a thorn in retaining such customers. The MonthlyCharges trend in the last 7 years has exprienced a decline in revenue, with churned customers generating an average of 74 dollars which is relative to the non churned customers who have spent 61 dollars.\n",
    "\n",
    "The missing values in TotalCharges were imputed using SimpleImputer. Initially, I thought I would infer them based on the MonthlyCharges, but I noticed that the monthly charges even for the same duration and set of services differ slightly. Imputation didn't shift the median much. I also imputed the \"missing\" values for MultipleLines and various Internet services as I was under the assumption that they were missing at random. But, I was advised that this wasn't the case, so after merging the datasets, I filled them with a response of \"No\".\n",
    "I skipped the idea of imputing them using LogisticRegression as it would have been overkill for this problem.\n",
    "In the feature engineering step, I created num_day derived by taking the difference between EndDate and BeginDate. Additionally, I created num_pmt which is a ratio of TotalCharges/MonthlyCharges. num_services, which adds up the various services for a customer depending on whether they've answered \"Yes\" or \"No\". Date features such as year, month and dayofweek were extracted from BeginDate.\n",
    "\n",
    "To avoid data leakage, I stratfied and split the dataset into train and test into a ratio of 80:20. I create a copy of this dataset, as I wanted to test whether num_days caused any leakage; I applied Oridinal Encoding for theTypeandPaymentMethod` features. I also scaled the numerical features such as num_days, num_pmt, num_services, MonthlyCharges, TotalCharges, including the date features. I One-hot encoded the boolean features.\n",
    "\n",
    "Excluding the Dummy model, I built 6 models using LogisticRegression, RandomForestClassifier and CatBoostClassifier. Each model was trained on the 2 datasets. I used 5-fold cross validation during GridSearch to identify useful hyperparameters for the respective models. Only 1 or 2 hyperparameters were tuned to save time.\n",
    "With leakage, the LogisticRegression model and CatBoost hit 99 percent AUC ROC on the test-set. Although the former completed faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps skipped\n",
    "\n",
    "Upsampling because this only slightly improved the AUC, and after a point was causing the RandomForest and CatBoost to overfit to the train set. num_days, month and dayofweek didn't have much signal strength relative to num_pmt and year.\n",
    "Imputation using LogisticRegression as this would have been overkill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenges\n",
    "\n",
    "The difficulties I encountered were after I removed the target leaked features such as num_days, num_pmt, year, month\n",
    "and dayofweek all in one go.\n",
    "I removed num_pmt, num_days and the Date features year, month and dayofweek, and retrained the model. This reduced the score for LogisticRegression the other models seem to overfit.\n",
    "To address this, I added upsampling to the mix and changed the upsampling ratio, however, it only ended up overfitting the RandomForest and CatBoost models, and it helped the LogisticRegression models.\n",
    "I changed the Ordinal features to use One-hot encoding, but that didn't help improve the performance.\n",
    "I changed the train/test split to 90:10, and noticed a slight improvement.\n",
    "I played with additional hyperparameters in RandomForest and CatBoost such as max_depth/depth, min_sample_leafs/l2_leaf_reg. min_sample_leafs helped reduce overfitting in RandomForest significantly, but l2_leaf_reg didn't help reduce overfitting. And a similar argument in CatBoost threw an error stating that the feature is not supported on CPU.\n",
    "After more than two hours, I decided to reuse only month and dayofweek along with num_pmt and num_days. Surprisingly, this helped increase AUC using LogisticRegression.\n",
    "I dropped upsampling from the mix, and removed dayofweek to see if this would affect the score, but it didn't.\n",
    "This time, I dropped month, dayofweek and num_days. I re-introduced year into the mix along withnum_pmt.\n",
    "This boosted my AUC to 96 percent using Logistic Regression the Random Forest decreased slightly and the Catboost regresso\n",
    "\n",
    " What worked was increasing the train-test split to 90:10, removing num_days, month, and dayofweek, and retaining num_pmt and year with the other one-hot encoded features. Upsampling didn't help to improve the performance beyond this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key steps taken\n",
    "\n",
    "Feature engineering - Finding a golden feature which improves the signal to noise ratio helped me a lot.\n",
    "Playing with train-test split also helped. Avoiding leakage by splitting the data into train/test before scaling and applying ordinal enconding also helped. Hyperparameter tuning along with 5-fold cross validation made me comfortable knowing that the model would generalize better to new data. Not to forget, EDA also helped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model\n",
    "The best model is the Logistic Regression2 model. I did 7 models a dummy model, a Logistic Regression (0), Random Forest (2), and catboost(4) were done but had Target Leakage. so I also did them without leakage, and that is Logistic Regression (1), Random Forest(3) and the Catboost (5). of all of these the Logistic Regression2 (1) yielded the best results. at 97 percent for the auc time.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
